<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head><meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<meta name="viewport" content="width=800">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    .hp-photo{ width:240px; height:240px; border-radius:240px; -webkit-border-radius:240px; -moz-border-radius:240px; }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 24px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 15px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
    </style>

    <title>Xinjie Zhou</title>
    <!--<link rel="stylesheet" type="text/css" href="/imgs/css" >-->
    <!-- <link rel="icon" type="image/png" href="./images/zju.png"> -->
    <link rel="icon" type="image/png" href="./images/hit.png">
    <!-- <link rel="shortcut icon" type="image/vnd.microsoft.icon" href="./images/zju.png"> -->
</head>

<body>
<table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
<tbody>
<tr>
<td>


    <!--SECTION 1 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody><tr>
              <td width="68%" valign="middle">
                <p align="center"><name>Xinjie Zhou (周新杰)</name></p>
                    I am a Master student (Sep. 2020 - Jul. 2022) in the <a href="http://sa.hit.edu.cn/">School of Astronautics</a>
                    at <a href="http://http://www.hit.edu.cn/">Harbin Institute of Technology</a>,
                    supervised by <a href="http://homepage.hit.edu.cn/gaohuijun"> Prof. Huijun Gao</a>.
                    I also obtained a B.Eng from <a href="http://en.hit.edu.cn/"> Harbin Institute Of Technology </a>.

                    </br></br>

                    <!-- <strong><font color="red">Looking for a 2022 PhD position in computer vision / robotics perception! Welcome to contact me! </font></strong> -->

	            </br>
              </td>
			        <td align="right"> <img class="hp-photo" src="./images/zxj.jpg" style="width: 150; height: 210;"></td></tr>
            </tbody>
          </table>

    <!--SECTION 2 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
         <td>
         <heading>Research Interests</heading>
          <p align="justify">I'm interested in <strong>SLAM</strong> and robotics. Currently I'm working on <strong>vehicle localization technology based on multi-sensor fusion</strong>.
               I hope to build high quality point cloud map and get robust and precised ego-motion estimation. My research goal is to help the robot to
               realize robust and precise localization with the help of multi-sensor,including LiDAR,camera,IMU,GNSS.
          <!--</br></br>-->
      <!--<span class="highlight"><strong>Internship Position: </strong> If you're interested in ...</span> -->
      </p>
      </td></tr>
      </tbody>
   </table>

    <!-- SECTION 3 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td><heading>Research Platform</heading>
        </td>
        </tr></tbody>
    </table>

    <!--SECTION 5 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

      <tbody><tr>
          <td width="20%"><img src="./images/platform.png" alt="PontTuset" width="250" style="border-style: none"></td>
          <td width="80%" valign="middle">
            <papertitle>An autonomous driving car equipped with LiDAR, camera, IMU and RTK</papertitle>
              </p><p></p>
              <p align="justify" style="font-size:13px"> <strong>Car Platform:</strong> Trumpchi</p>
              <p align="justify" style="font-size:13px"> <strong>LiDAR:</strong> RS-LiDAR-32*1, RS-LiDAR-16*2</p>
              <p align="justify" style="font-size:13px"> <strong>Monocular Camera:</strong> A5201M/CG50</p>
              <p align="justify" style="font-size:13px"> <strong>Integrated Navigation System:</strong> PwrPak7</p>
              <a href="./videos/platform/ad_car_demo.mp4">Autonomous Driving Demo Video</a>
              </td>
      </tr>

    <!-- SECTION 3 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td><heading>Research Experience</heading>
        </td>
        </tr></tbody>
  </table>


    <!--SECTION 5 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

      <tbody><tr>
          <td width="20%"><img src="./images/mapping/mapping_10s.gif" alt="PontTuset" width="250" style="border-style: none"></td>
          <td width="80%" valign="top">
            <p align="justify" style="font-size:13px"> <strong>------------------------------------------------------------------------------------------</strong> </p>
            <papertitle>Mapping framework based on multi-sensor fusion with LiDAR, IMU and GNSS</papertitle>
              </p><p></p>
              <p align="justify" style="font-size:13px"> 2020.11-2021.02 </p>
              <p align="justify" style="font-size:13px"> <strong>【数据预处理】:</strong> 对各种传感器数据进行<strong>时间戳同步</strong>，基于<strong>LiDAR</strong>与<strong>RTK</strong>外参将<strong>RTK</strong>位姿转换到<strong>LiDAR坐标系</strong>，作为位姿参考</p>
              <p align="justify" style="font-size:13px"> <strong>【前端】:</strong> 维护一个固定帧数的<strong>局部地图</strong>，采用NDT对当前帧激光点云做<strong>scan-to-map</strong>的匹配，获取<strong>前端激光里程计</strong></p>
              <p align="justify" style="font-size:13px"> <strong>【回环检测】:</strong> 基于手写<strong>Scan Context</strong>方法查找当前帧的候选回环帧，并求取粗略位姿初值，进而用ICP求取回环约束</p>
              <p align="justify" style="font-size:13px"> <strong>【后端】:</strong> 利用<strong>G2O</strong>引入<strong>前端里程计帧间约束</strong>、 <strong>IMU帧间约束</strong>、 <strong>RTK对单帧的位置约束</strong>、 <strong>回环约束</strong>，对<strong>关键帧位姿</strong>进行优化</p>
              <p align="justify" style="font-size:13px"> <strong>【建图】:</strong> 执行<strong>全局位姿图优化</strong>后，根据<strong>优化后的关键帧位姿</strong>拼接每个<strong>关键帧</strong>对应的的激光点云，得到完整的<strong>点云地图</strong></p>
              <p align="justify" style="font-size:13px"> <strong>【验证】:</strong> 在公开的<strong>KITTI数据集</strong>和<strong>UrbanNav香港数据集</strong>上测试，本算法获取的<strong>点云地图</strong>可以很好地支持后续的<strong>定位需求</strong></p>
              <p align="justify" style="font-size:13px"> <strong>【TO DO/改进】:</strong> 前端采用<strong>MULLS-ICP</strong>提取点、线、面特征，提高构建的<strong>约束</strong>的合理性，并对<strong>动态物体</strong>进行一定滤波，保证建图效果不受<strong>动态物体</strong>影响</p>
              <strong></strong>
              </td>
      </tr>

        <!--SECTION 5 -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

          <tbody><tr>
              <td width="20%"><img src="./images/localization_initialization/localization_init_on_map.gif" alt="PontTuset" width="250" style="border-style: none"></td>
              <td width="80%" valign="top">
                <p align="justify" style="font-size:13px"> <strong>------------------------------------------------------------------------------------------</strong> </p>
                <papertitle>Global pose initialization on pre-built point cloud map</papertitle>
                  </p><p></p>
                  <p align="justify" style="font-size:13px"> 2021.03 </p>
                  <p align="justify" style="font-size:13px"> <strong>【基于GNSS】:</strong>  </p>
                  <p align="justify" style="font-size:13px"> 记录<strong>建图时</strong><strong>第一帧</strong>有效点云数据对应的<strong>GNSS数据</strong>，在<strong>地图上初始化时</strong>通过调用<strong>GeographicLib库</strong>将<strong>该GNSS数据</strong>设为<strong>原点</strong>，<strong>初始化</strong>时的GNSS数据通过<strong>GeographicLib库</strong>将<strong>GNSS数据</strong>转化为<strong>ENU坐标系</strong>下的数据，从而得到<strong>初始化时</strong><strong>载体相对于地图坐标系</strong>的<strong>位姿信息</strong></p>
                  <p align="justify" style="font-size:13px"> <strong>【基于Scan Context场景识别】:</strong> </p>
                  <p align="justify" style="font-size:13px"> <strong> 建图时 </strong>存储关键帧对应的Scan Context与位姿信息，<strong>初始化</strong>时查找<strong>最相似的关键帧Scan Context</strong>并进行位姿匹配进而得到<strong>初始化</strong>时位姿估计的初值，进而进一步进行点云配准得到<strong>当前位姿</strong>的精确估计值</p>
                  </td>
          </tr>
    <!--SECTION 6 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

      <tbody><tr>
          <td width="20%"><img src="./images/ESKF_localization/ESKF_HK_10s.gif" alt="PontTuset" width="250" style="border-style: none"></td>
          <td width="80%" valign="top">
            <p align="justify" style="font-size:13px"> <strong>------------------------------------------------------------------------------------------</strong> </p>
            <papertitle>Localization based on pre-built point cloud map with Error-State Kalman Filter</papertitle>
              </p><p></p>
              <p align="justify" style="font-size:13px"> 2021.03-2021.04 </p>
              <p align="justify" style="font-size:13px"> <strong>【地图上定位初始化】:</strong> 基于<strong>GNSS</strong>或<strong>Scan Context</strong>方法(使用初始scan查询<strong>Scan Context</strong>索引)完成<strong>基于点云地图定位的初始化</strong></p>
              <p align="justify" style="font-size:13px"> <strong>【ESKF预测步】:</strong> 通过<strong>IMU数据</strong>利用<strong>中值积分</strong>方法完成<strong>惯性解算</strong>，<strong>解算结果</strong>作为当前帧<strong>位置、姿态、速度</strong>的<strong>先验值</strong></p>
              <p align="justify" style="font-size:13px"> <strong>【ESKF校正步】:</strong> 有<strong>观测</strong>（<strong>当前帧点云</strong>和<strong>点云地图</strong>匹配获取位姿）时求解<strong>误差状态</strong>的<strong>观测值</strong>，求解<strong>卡尔曼增益</strong>、<strong>后验协方差</strong>和<strong>后验误差状态值</strong>；无<strong>观测</strong>时，<strong>后验值</strong>直接等于<strong>先验值</strong></p>
              <p align="justify" style="font-size:13px"> <strong>【求解状态量后验值】:</strong> 根据<strong>后验误差状态量</strong>的值更新<strong>位姿、速度、IMU bias</strong>的<strong>后验值</strong></p>
              <p align="justify" style="font-size:13px"> <strong>【验证】:</strong> 在公开的<strong>KITTI数据集</strong>和<strong>UrbanNav香港数据集</strong>上测试，本算法基于<strong>点云地图</strong>可以获取很高的定位精度</p>
              </td>
      </tr>

  </table>

      <!--SECTION 7 -->
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

        <tbody><tr>
            <td width="20%"><img src="./images/sliding_window_localization/SlidingWindow_10s.gif" alt="PontTuset" width="250" style="border-style: none"></td>
            <td width="80%" valign="top">
            <p align="justify" style="font-size:13px"> <strong>------------------------------------------------------------------------------------------</strong> </p>
              <papertitle>Localization based on pre-built point cloud map with Sliding Window and Graph Optimization</papertitle>
  
                </p><p></p>
                <p align="justify" style="font-size:13px"> 2021.05-2021.08 </p>
                <p align="justify" style="font-size:13px"> <strong>【地图上定位初始化】:</strong> 基于<strong>GNSS</strong>或<strong>Scan Context</strong>方法(使用初始scan查询<strong>Scan Context</strong>索引)完成<strong>基于点云地图定位的初始化</strong></p>
                <p align="justify" style="font-size:13px"> <strong>【前端里程计】:</strong> 通过<strong>当前帧点云</strong>和<strong>地图</strong>匹配获取前端里程计</p>
                <p align="justify" style="font-size:13px"> <strong>【基于滑动窗口的后端优化】:</strong> 维护一个固定长度的<strong>滑动窗口</strong>来保证定位的实时性，引入<strong>前端里程计的帧间约束</strong>、<strong>IMU预积分帧间约束</strong>和<strong>边缘化产生的约束</strong>对状态进行<strong>滑窗优化</strong>，获得<strong>实时</strong>的定位结果</p>
                <p align="justify" style="font-size:13px"> <strong>【验证】:</strong> 在公开的<strong>KITTI数据集</strong>和<strong>UrbanNav香港数据集</strong>上测试，本算法基于<strong>点云地图</strong>可以获取较高的定位精度</p>
                </td>
        </tr>
  
    </table>

        <!--SECTION 4 -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

          <tbody><tr>
              <td width="20%"><img src="./images/TVL-SLAM/pipeline.png" alt="PontTuset" width="250" style="border-style: none"></td>
              <td width="80%" valign="top">
            <p align="justify" style="font-size:13px"> <strong>------------------------------------------------------------------------------------------</strong> </p>
                <papertitle>Tightly coupled Visual-LiDAR SLAM</papertitle>
                  </p><p></p>
                  <p align="justify" style="font-size:13px"> 2020.03-2020.09 </p>
                  <p align="justify" style="font-size:13px"> 设计<strong>激光雷达</strong>和<strong>相机紧耦合</strong>的六自由度位姿估计算法，解决实际情况中基于<strong>激光雷达</strong>和基于<strong>相机</strong>的定位系统的不足</p>
                  <p align="justify" style="font-size:13px"> 1.设计<strong>点云-图像的数据关联</strong>算法，实现<strong>视觉特征点</strong>的提取、跟踪，并结合点云数据<strong>恢复</strong>出<strong>3D视觉特征点</strong></p>
                  <p align="justify" style="font-size:13px"> 2.优化地面分割算法，并在进行点云物体分割后提取激光特征点，以降低计算量，得到全局一致的轨迹和地图</p>
                  <p align="justify" style="font-size:13px"> 3.建立<strong>视觉特征点</strong>之间以及<strong>激光特征点</strong>之间的约束关系，使用L-M算法优化求解</p>
                  <p align="justify" style="font-size:13px"> 4.实现<strong>近邻</strong>的<strong>闭环检测</strong>和<strong>全局位姿图优化</strong>，得到<strong>全局一致</strong>的<strong>轨迹</strong>和<strong>地图</strong></p>
                  <p align="justify" style="font-size:13px"> <strong>【评价】:</strong> 此方法可以<strong>实时</strong>地估计出无人车地位姿，缓解激光雷达在<strong>结构特征缺失地场景</strong>下约束不足的问题，精度超过开源的A-LOAM、LeGO-LOAM</p>    
                  </td>
          </tr>

        <!--SECTION 8 -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr>
             <td>
             <heading>About Me</heading>
                 <p> <strong>Skills</strong>: C / C ++, Linux, ROS, OpenCV, PCL, g2o, ceres</p>
                 <p> <strong>Languages</strong>: Chinese: Native. English: CET-6: 534, CET-4: 614.</p>
          </td></tr>
          </tbody>
       </table>

</td>
</tr>
</tbody>
</table>
</body>
</html>
